- id: file_based_caching
  priority: P0
  status: todo
  description: >
    Implement a simple, deterministic, file-based cache with a TTL. This
    is the foundational enabler for all multi-stage workflows and must be
    completed before other features that rely on it.
  details:
    - Use a SHA256 hash of the URL as the cache key (filename).
    - Store cache files in a dedicated directory (e.g., ~/.cache/llm-web-parser/).
    - Before fetching, check if a cached file exists and if its modification
      time is within the TTL.
    - Add a `--cache-ttl` flag to configure the cache duration (e.g., "1h", "30m").
  impact: >
    Massive performance and usability win. Makes iterative exploration
    fast and cheap. Unblocks the entire multi-stage analysis vision.

- id: extract_subcommand_filtered
  priority: P0
  status: in_progress
  description: >
    Add 'extract' subcommand to filter existing JSON files, enabling
    powerful, LLM-driven deep-dives into content.
  details:
    - Implement a powerful `--extract-strategy` flag instead of multiple
      separate filter flags (e.g., --strategy="type:paragraph|code,conf:>=0.7").
    - Add Table of Contents (TOC) extraction during parsing to enable
      section-based extraction (e.g., --strategy="section:'API Reference'").
    - Add Chunk Boundary detection to allow for token-budgeted extraction
      (e.g., --max-tokens=5000), splitting content at natural breaks.
    - Extracted blocks must carry a "Structural Lineage" (source URL, block ID,
      parent ID, heading ancestry) to enable precise follow-up queries.
  impact: >
    Completes the core `minimal -> summary -> extract` workflow. This command
    is the surgical tool an LLM uses in the final stage of analysis.

- id: golangci_lint_fixes
  priority: P0
  status: in_progress
  assigned_to: daniel
  description: Fix all remaining golangci-lint issues to establish code quality baseline.

- id: documentation_structure
  priority: P0
  status: todo
  description: >
    Create professional documentation for contributors and for LLM consumption.
