# llm-web-parser Performance Test Results

## Test Environment
- Date: 2026-01-15
- Workers: 8 (default)
- Parse Mode: minimal (metadata only)
- Timeout per URL: 5 seconds

## Fresh Fetch Performance

### Test 1: 51 URLs (Tech/Dev Sites)
- **Time: 2.227 seconds**
- **Success Rate: 94.1% (48/51)**
- **Throughput: 22.9 URLs/second**
- Failed: java.com (403), npmjs.com (403), crates.io (404)

### Test 2: 80 URLs (Mixed Tech Sites)
- **Time: 21.131 seconds**
- **Success Rate: 98.8% (79/80)**
- **Throughput: 3.8 URLs/second**
- Failed: gnu.org (403)
- Note: Slower throughput due to some sites hitting 5-second timeout

### Test 3: 29 URLs (OS/Tools Sites)
- **Time: 1.587 seconds**
- **Success Rate: 96.6% (28/29)**
- **Throughput: 18.2 URLs/second**
- Failed: gnu.org (403)

## Cache Hit Performance

### Same URL List (Session Cache)
- **51 URLs: 0.052 seconds (52ms)**
- **80 URLs: 0.014 seconds (14ms)**
- **Effectively instant** âš¡

## Key Findings

### âœ… Strengths
1. **Best case: 22.9 URLs/second** (fast-responding sites)
2. **Cache hits are instant** (<100ms for 80 URLs)
3. **High success rate** (94-98% across all tests)
4. **Parallel processing works well** (8 workers)

### âš ï¸ Bottlenecks
1. **Slow sites impact total time** heavily
   - 80 URLs with some slow sites: 21 seconds
   - 51 URLs with mostly fast sites: 2.2 seconds
2. **5-second timeout** is the limiting factor
   - A single slow URL can add 5 seconds to total time
3. **Throughput varies widely**: 3.8 - 22.9 URLs/sec
   - Depends entirely on site response times

## Real-World Estimates

### For 40 URLs (LLM typical batch)
- **Best case**: ~2 seconds (all fast sites)
- **Worst case**: ~50 seconds (multiple timeouts)
- **Typical**: ~5-10 seconds (mixed sites)

### For 80 URLs (Large batch)
- **Best case**: ~4 seconds (all fast sites)
- **Worst case**: ~100 seconds (multiple timeouts)
- **Typical**: ~10-20 seconds (mixed sites)

### Cache Hits (Same URL set)
- **Any size**: <100ms ðŸš€

## Recommendations

### For LLM Workflows
1. **Use minimal mode for initial scan** âœ… (already default)
   - Fast metadata-only parsing
   - Then deep-dive on high-confidence URLs with full-parse
   
2. **Batch sizes**:
   - 40-50 URLs: Optimal for speed + coverage
   - 80+ URLs: Expect 10-20 second wait
   
3. **Two-stage workflow** (already supported):
   ```bash
   # Stage 1: Fast scan (40-50 URLs in 2-5 seconds)
   lwp fetch --urls "url1,...,url50"
   
   # Stage 2: Deep dive on high-confidence URLs
   lwp fetch --urls "$(yq filter)" --features full-parse
   ```

### Performance Tuning (Future)
- Could add `--fast-fail` flag (1-second timeout vs 5-second)
- Could add `--max-urls` cap to prevent accidental large batches
- Could show progress indicator for large batches

## Conclusion

**Target: Can we handle 80 URLs in <5 seconds?**
- âŒ No for fresh fetches (10-20 seconds typical)
- âœ… Yes for cache hits (<100ms)

**However:**
- 40-50 URLs in 2-5 seconds is very achievable âœ…
- Cache hits make repeated queries instant âœ…
- Success rate is excellent (95%+) âœ…

**Recommendation:** Tool is ready for production LLM use with 40-50 URL batches.
